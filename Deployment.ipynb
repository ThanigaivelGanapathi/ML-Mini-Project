{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea69ae7-d06e-4f80-86dc-45ed494c027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ec85c3-6808-44b1-a635-7d82c1deec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acff957b-b687-4522-8157-e44928734461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Eligible\n"
     ]
    }
   ],
   "source": [
    "with open('model_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "age = 45\n",
    "income =50000\n",
    "loanAmount = 100000\n",
    "creditScore = 350\n",
    "interest = 10\n",
    "\n",
    "scaler = data['scaler']\n",
    "selector = data['selector']\n",
    "model = data['model']\n",
    "\n",
    "new_data = np.array([[age, income, loanAmount, creditScore, interest]])\n",
    "\n",
    "#X_new_input = selector.transform(new_data)\n",
    "X_new_scaled = scaler.transform(new_data)\n",
    "pred = model.predict(X_new_scaled)\n",
    "predict = \"Eligible\" if pred[0] == 1 else \"Not Eligible\"\n",
    "print(predict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2d1ba95-e645-41b2-84e3-38f973cee0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('model_data.pkl', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# scaler = data['scaler']\n",
    "# selector = data['selector']\n",
    "# model = data['model']\n",
    "\n",
    "# new_data = np.array([[age, income, loanAmount, creditScore, interest]])\n",
    "\n",
    "# #X_new_input = selector.transform(new_data)\n",
    "# X_new_scaled = scaler.transform(new_data)\n",
    "# pred = model.predict(X_new_scaled)\n",
    "# predict = \"Eligible\" if pred[0] == 1 else \"Not Eligible\"\n",
    "# print(predict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da51851d-eca4-4b5e-89ad-044277d311bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('model_data.pkl', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# scaler = data['scaler']\n",
    "# model = data['model']\n",
    "\n",
    "# # Example usage\n",
    "# X_new_scaled = scaler.transform(X_new)\n",
    "# prediction = model.predict(X_new_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e72cfa29-d085-4a62-85cd-900c9fe12662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Use the full data\n",
    "# X_selected = selector.transform(features)\n",
    "\n",
    "# # Scale full data\n",
    "# X_scaled = scaler.fit_transform(X_selected)\n",
    "\n",
    "# # Train final model\n",
    "# final_model = RandomForestClassifier()\n",
    "# final_model.fit(X_scaled, dependent)\n",
    "\n",
    "# # Save everything\n",
    "# bundle = {\n",
    "#     'scaler': scaler,\n",
    "#     'selector': selector,\n",
    "#     'model': final_model\n",
    "# }\n",
    "\n",
    "# with open('final_model_bundle.pkl', 'wb') as f:\n",
    "#     pickle.dump(bundle, f)\n",
    "\n",
    "# print(\"Final model, scaler, and selector saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11fdaf0a-e223-45d6-b1a7-b5686a41ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load everything back\n",
    "# with open('final_model_bundle.pkl', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "\n",
    "# scaler = data['scaler']\n",
    "# selector = data['selector']\n",
    "# model = data['model']\n",
    "\n",
    "# # For new data\n",
    "# X_new_input = selector.transform(new_data)\n",
    "# X_new_scaled = scaler.transform(X_new_input)\n",
    "# pred = model.predict(X_new_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326188f1-a80e-4fcf-bec2-aea4a51d9bf7",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06c5bae8-0a8a-4c04-bc23-01cc4d4e5a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lg =[]\n",
    "# svm =[]\n",
    "# svm_nl =[]\n",
    "# knn =[]\n",
    "# dt =[]\n",
    "# nb =[]\n",
    "# rf =[]\n",
    "\n",
    "# #Splitting into training and testing datasets\n",
    "# def Split_To_Training_Testing(features):\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(features,dependent,test_size = 0.20,random_state = 0)\n",
    "#     sc = StandardScaler()\n",
    "#     x_train = sc.fit_transform(x_train)\n",
    "#     x_test = sc.transform(x_test)     \n",
    "#     return x_train, x_test, y_train, y_test\n",
    "\n",
    "# #Select K Best Algorithm\n",
    "# def selectKBest(n):    \n",
    "#     kbest = SelectKBest(score_func  = chi2, k = n)\n",
    "#     kbestModel = kbest.fit(independent,dependent)\n",
    "#     features = kbest.transform(independent)    \n",
    "#     return build_model(features)    \n",
    "\n",
    "# #Classificaiton Models\n",
    "# def build_model(features):   \n",
    "#     x_train, x_test, y_train, y_test =  Split_To_Training_Testing(features)\n",
    "#     logistic_regression(x_train, x_test, y_train, y_test)    \n",
    "#     svm_linear(x_train, x_test, y_train, y_test)\n",
    "#     svm_non_linear(x_train, x_test, y_train, y_test)\n",
    "#     knn_regresssion(x_train, x_test, y_train, y_test)\n",
    "#     decisionTree(x_train, x_test, y_train, y_test)\n",
    "#     naive_baye(x_train, x_test, y_train, y_test)\n",
    "#     random_forest(x_train, x_test, y_train, y_test)  \n",
    "#     dataframe1 = generateTbl()\n",
    "#     return dataframe1 \n",
    "    \n",
    "# def logistic_regression(x_train, x_test, y_train, y_test):     \n",
    "#     global lg\n",
    "#     lg.clear()\n",
    "#     lg_regression = LogisticRegression(random_state = 42)\n",
    "#     lg_regression.fit(x_train,y_train)\n",
    "#     y_pred = lg_regression.predict(x_test)\n",
    "#     lg_cm = confusion_matrix(y_test, y_pred)\n",
    "#     lg_accuracy = accuracy_score(y_test, y_pred )\n",
    "#     lg_classification = classification_report(y_test, y_pred)    \n",
    "#     lg.append(lg_accuracy)   \n",
    "\n",
    "# def svm_linear(x_train, x_test, y_train, y_test):\n",
    "#     global lg\n",
    "#     svm.clear()\n",
    "#     svm_regression = SVC(kernel = 'linear', random_state = 0)\n",
    "#     svm_regression.fit(x_train,y_train)\n",
    "#     y_pred = svm_regression.predict(x_test)\n",
    "#     svm_cm = confusion_matrix(y_test, y_pred)\n",
    "#     svm_accuracy = accuracy_score(y_test, y_pred )\n",
    "#     svm_classification = classification_report(y_test, y_pred)\n",
    "#     svm.append(svm_accuracy)\n",
    "    \n",
    "# def svm_non_linear(x_train, x_test, y_train, y_test):\n",
    "#     global svm_nl\n",
    "#     svm_nl.clear()\n",
    "#     svmnl_regression = SVC(kernel = 'rbf', random_state = 0)\n",
    "#     svmnl_regression.fit(x_train,y_train)\n",
    "#     y_pred = svmnl_regression.predict(x_test)\n",
    "#     svmnl_cm = confusion_matrix(y_test, y_pred)\n",
    "#     svmnl_accuracy = accuracy_score(y_test, y_pred )\n",
    "#     svmnl_classification = classification_report(y_test, y_pred)\n",
    "#     svm_nl.append(svmnl_accuracy)\n",
    "     \n",
    "    \n",
    "# def knn_regresssion(x_train, x_test, y_train, y_test):\n",
    "#     global knn\n",
    "#     knn.clear()\n",
    "#     knn_regression =  KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "#     knn_regression.fit(x_train,y_train)\n",
    "#     y_pred = knn_regression.predict(x_test)\n",
    "#     knn_cm = confusion_matrix(y_test, y_pred)\n",
    "#     knn_accuracy = accuracy_score(y_test, y_pred )\n",
    "#     knn_classification = classification_report(y_test, y_pred)  \n",
    "#     knn.append(knn_accuracy)\n",
    "\n",
    "    \n",
    "# def decisionTree(x_train, x_test, y_train, y_test):  \n",
    "#     global dt\n",
    "#     dt.clear()\n",
    "#     des_regression =  DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "#     des_regression.fit(x_train,y_train)\n",
    "#     y_pred = des_regression.predict(x_test)\n",
    "#     des_cm = confusion_matrix(y_test, y_pred)\n",
    "#     des_accuracy = accuracy_score(y_test, y_pred )\n",
    "#     des_classification = classification_report(y_test, y_pred)\n",
    "#     dt.append(des_accuracy)    \n",
    "    \n",
    "# def naive_baye(x_train, x_test, y_train, y_test):   \n",
    "#     global nb\n",
    "#     nb.clear()\n",
    "#     nav_regression = GaussianNB()\n",
    "#     nav_regression.fit(x_train,y_train)\n",
    "#     y_pred = nav_regression.predict(x_test)\n",
    "#     nav_cm = confusion_matrix(y_test, y_pred)\n",
    "#     nav_accuracy = accuracy_score(y_test, y_pred )\n",
    "#     nav_classification = classification_report(y_test, y_pred)\n",
    "#     nb.append(nav_accuracy)        \n",
    "\n",
    "    \n",
    "# def random_forest(x_train, x_test, y_train, y_test):\n",
    "#     global rf\n",
    "#     rf.clear()\n",
    "#     rf_regression = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "#     rf_regression.fit(x_train,y_train)\n",
    "#     y_pred = rf_regression.predict(x_test)\n",
    "#     rf_cm = confusion_matrix(y_test, y_pred)\n",
    "#     rf_accuracy = accuracy_score(y_test, y_pred )\n",
    "#     rf_classification = classification_report(y_test, y_pred)\n",
    "#     rf.append(rf_accuracy)     \n",
    "\n",
    "# def generateTbl():\n",
    "#     result=dataframe=pd.DataFrame(index=['ChiSquare'],columns=['Logistic','SVMl','SVMnl','KNN','Navie','Decision','Random'])\n",
    "#     for number,index in enumerate(dataframe.index):   \n",
    "#         dataframe['Logistic'][index]=round(lg[number],2)\n",
    "#         dataframe['SVMl'][index]=round(svm[number],2) \n",
    "#         dataframe['SVMnl'][index]=round(svm_nl[number],2) \n",
    "#         dataframe['KNN'][index]=round(knn[number],2) \n",
    "#         dataframe['Navie'][index]=round(nb[number],2) \n",
    "#         dataframe['Decision'][index]=round(dt[number],2) \n",
    "#         dataframe['Random'][index]=round(rf[number],2) \n",
    "#     return dataframe     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ca09ba-d0b0-4b50-bc3a-17012fcd2890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # K = 5\n",
    "# dataframe = selectKBest(5)\n",
    "# dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4344811f-07c2-4125-ad30-886e5ac28f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
